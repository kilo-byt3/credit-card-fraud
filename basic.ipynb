{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE, ADASYN\n",
    "from imblearn.combine import SMOTETomek\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_predict\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.metrics import classification_report\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 219129 entries, 0 to 219128\n",
      "Data columns (total 32 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   id      219129 non-null  int64  \n",
      " 1   Time    219129 non-null  float64\n",
      " 2   V1      219129 non-null  float64\n",
      " 3   V2      219129 non-null  float64\n",
      " 4   V3      219129 non-null  float64\n",
      " 5   V4      219129 non-null  float64\n",
      " 6   V5      219129 non-null  float64\n",
      " 7   V6      219129 non-null  float64\n",
      " 8   V7      219129 non-null  float64\n",
      " 9   V8      219129 non-null  float64\n",
      " 10  V9      219129 non-null  float64\n",
      " 11  V10     219129 non-null  float64\n",
      " 12  V11     219129 non-null  float64\n",
      " 13  V12     219129 non-null  float64\n",
      " 14  V13     219129 non-null  float64\n",
      " 15  V14     219129 non-null  float64\n",
      " 16  V15     219129 non-null  float64\n",
      " 17  V16     219129 non-null  float64\n",
      " 18  V17     219129 non-null  float64\n",
      " 19  V18     219129 non-null  float64\n",
      " 20  V19     219129 non-null  float64\n",
      " 21  V20     219129 non-null  float64\n",
      " 22  V21     219129 non-null  float64\n",
      " 23  V22     219129 non-null  float64\n",
      " 24  V23     219129 non-null  float64\n",
      " 25  V24     219129 non-null  float64\n",
      " 26  V25     219129 non-null  float64\n",
      " 27  V26     219129 non-null  float64\n",
      " 28  V27     219129 non-null  float64\n",
      " 29  V28     219129 non-null  float64\n",
      " 30  Amount  219129 non-null  float64\n",
      " 31  Class   219129 non-null  int64  \n",
      "dtypes: float64(30), int64(2)\n",
      "memory usage: 53.5 MB\n",
      "None\n",
      "                  id           Time             V1             V2  \\\n",
      "count  219129.000000  219129.000000  219129.000000  219129.000000   \n",
      "mean   109564.000000   62377.415376       0.096008       0.048345   \n",
      "std     63257.237906   25620.348569       1.395425       1.159805   \n",
      "min         0.000000       0.000000     -29.807725     -44.247914   \n",
      "25%     54782.000000   47933.000000      -0.846135      -0.573728   \n",
      "50%    109564.000000   63189.000000       0.385913       0.046937   \n",
      "75%    164346.000000   77519.000000       1.190661       0.814145   \n",
      "max    219128.000000  120580.000000       2.430494      16.068473   \n",
      "\n",
      "                  V3             V4             V5             V6  \\\n",
      "count  219129.000000  219129.000000  219129.000000  219129.000000   \n",
      "mean        0.592102       0.069273      -0.161555       0.133688   \n",
      "std         1.132884       1.253125       1.069530       1.202411   \n",
      "min       -19.722872      -5.263650     -37.591259     -25.659750   \n",
      "25%        -0.027154      -0.769256      -0.847346      -0.631835   \n",
      "50%         0.735895       0.064856      -0.229929      -0.087778   \n",
      "75%         1.306110       0.919353       0.356856       0.482388   \n",
      "max         6.145578      12.547997      34.581260      16.233967   \n",
      "\n",
      "                  V7             V8  ...            V21            V22  \\\n",
      "count  219129.000000  219129.000000  ...  219129.000000  219129.000000   \n",
      "mean       -0.128224       0.149534  ...      -0.031064      -0.050852   \n",
      "std         0.817207       0.716212  ...       0.422777       0.597812   \n",
      "min       -31.179799     -28.903442  ...     -14.689621      -8.748979   \n",
      "25%        -0.646730      -0.095948  ...      -0.190418      -0.473099   \n",
      "50%        -0.098970       0.111219  ...      -0.042858      -0.032856   \n",
      "75%         0.385567       0.390976  ...       0.109187       0.354910   \n",
      "max        39.824099      18.270586  ...      22.062945       6.163541   \n",
      "\n",
      "                 V23            V24            V25            V26  \\\n",
      "count  219129.000000  219129.000000  219129.000000  219129.000000   \n",
      "mean       -0.050531      -0.002992       0.124005       0.009881   \n",
      "std         0.318175       0.593100       0.406741       0.473867   \n",
      "min       -11.958588      -2.836285      -3.958591      -1.858672   \n",
      "25%        -0.174478      -0.332540      -0.126080      -0.318330   \n",
      "50%        -0.063307       0.038708       0.145934      -0.086388   \n",
      "75%         0.060221       0.394566       0.402926       0.253869   \n",
      "max        12.734391       4.572739       3.111624       3.402344   \n",
      "\n",
      "                 V27            V28         Amount          Class  \n",
      "count  219129.000000  219129.000000  219129.000000  219129.000000  \n",
      "mean        0.014034       0.017313      66.359803       0.002140  \n",
      "std         0.233355       0.164859     150.795017       0.046214  \n",
      "min        -9.234767      -4.551680       0.000000       0.000000  \n",
      "25%        -0.050983      -0.009512       5.990000       0.000000  \n",
      "50%         0.015905       0.022163      21.900000       0.000000  \n",
      "75%         0.076814       0.066987      68.930000       0.000000  \n",
      "max        13.123618      23.263746    7475.000000       1.000000  \n",
      "\n",
      "[8 rows x 32 columns]\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(r'.\\data\\train.csv')\n",
    "test = pd.read_csv(r'.\\data\\test.csv')\n",
    "\n",
    "print(train.info())\n",
    "print(train.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = []\n",
    "\n",
    "for i in range(1,29):\n",
    "    features.append(f\"V{i}\")\n",
    "\n",
    "features = ['Time', 'Amount'] + features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 0\n",
    "end = 3600\n",
    "\n",
    "#train['Time'] = np.where(train['Time'] > 86400, train['Time'] - 86400, train['Time'])\n",
    "#test['Time'] = np.where(test['Time'] > 86400, test['Time'] - 86400, test['Time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampler(x, y, type, random_state=0):\n",
    "    xsmp, ysmp = -1, -1\n",
    "    match type:\n",
    "        case 0: xsmp, ysmp = RandomOverSampler(random_state=random_state).fit_resample(x,y)\n",
    "        case 1: xsmp, ysmp = SMOTE(random_state=random_state).fit_resample(x,y)\n",
    "        case 2: xsmp, ysmp = ADASYN(random_state=random_state).fit_resample(x,y)\n",
    "        case 3: xsmp, ysmp = SMOTETomek(random_state=random_state).fit_resample(x,y)\n",
    "    return xsmp, ysmp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrn, ytrn = train[features], train[['Class']]\n",
    "xtst = test[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Normalize Data         # 1. Sample Data\n",
    "# 2. Sample Data            # 2. Split Data\n",
    "# 3. Split Data             # 3. Normalize Data\n",
    "# 4. Model Selection        # 4. Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Normalize Data\n",
    "\n",
    "xtrn = MinMaxScaler().fit_transform(xtrn)\n",
    "\n",
    "# 2. Sample Data\n",
    "xtrn, ytrn = sampler(xtrn, ytrn, 2)\n",
    "\n",
    "# 3. Split Data\n",
    "xtrn, xvld, ytrn, yvld = train_test_split(xtrn, ytrn, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrn = pd.DataFrame(xtrn, columns=[features])\n",
    "xvld = pd.DataFrame(xvld, columns=[features])\n",
    "# xtst = pd.DataFrame(xtst, columns=[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Model Selection\n",
    "\n",
    "# a. Random Forest\n",
    "\n",
    "# model = RandomForestClassifier()\n",
    "# model.fit(xtrn, ytrn)\n",
    "# \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# b. RandomForest + Adaboost\n",
    "\n",
    "# rf = RandomForestClassifier()\n",
    "# model = AdaBoostClassifier(estimator=rf)\n",
    "# model.fit(xtrn, ytrn)\n",
    "# yvld_ = model.predict(xvld)\n",
    "\n",
    "# print(classification_report(yvld, yvld_))\n",
    "\n",
    "# pred = model.predict(xtst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c.RandomForest + Adabosst + KFold\n",
    "\n",
    "# n_splits = 10\n",
    "# kf = KFold(n_splits=n_splits)\n",
    "# rf = RandomForestClassifier()\n",
    "# model = AdaBoostClassifier(estimator=rf)\n",
    "\n",
    "# models = []\n",
    "# fold = 1\n",
    "# for train_indices, vld_indices in kf.split(xtrn):\n",
    "#     print(f\"Fold {fold}\")\n",
    "#     print(\"-----------------------------------------------\")\n",
    "#     fold+=1\n",
    "\n",
    "#     xtrn_, ytrn_ = pd.DataFrame(xtrn).iloc[train_indices], pd.DataFrame(ytrn).iloc[train_indices]\n",
    "#     xvld_, yvld_ = pd.DataFrame(xtrn).iloc[vld_indices], pd.DataFrame(ytrn).iloc[vld_indices]\n",
    "\n",
    "#     rf = RandomForestClassifier()\n",
    "#     model = AdaBoostClassifier(estimator=rf)\n",
    "\n",
    "#     model.fit(xtrn_, ytrn_)\n",
    "#     yprd_ = model.predict(xvld_)\n",
    "\n",
    "#     print(classification_report(yvld_, yprd_))\n",
    "#     models.append(model)\n",
    "#     print()\n",
    "\n",
    "#     predictions = []\n",
    "\n",
    "# for model in models:\n",
    "#   yprd = model.predict(xtst[features])\n",
    "#   predictions.append(yprd)\n",
    "# summ = np.zeros(shape=predictions[0].shape)\n",
    "\n",
    "# for p in predictions:\n",
    "#     summ+=p\n",
    "\n",
    "# summ = np.where(summ >=5, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d. Just XGB - Best\n",
    "\n",
    "# model = XGBClassifier()\n",
    "# model.fit(xtrn, ytrn)\n",
    "\n",
    "# yprd = model.predict(xvld)\n",
    "\n",
    "# print(classification_report(yvld, yprd))\n",
    "\n",
    "# pred = model.predict(xtst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#e. XGB + KFold\n",
    "\n",
    "# models = []\n",
    "# fold=1\n",
    "# kf = KFold(n_splits=10)\n",
    "# for trn_ind, vld_ind in kf.split(xtrn):\n",
    "#     xtrn_, ytrn_ = pd.DataFrame(xtrn).iloc[trn_ind], pd.DataFrame(ytrn).iloc[trn_ind]\n",
    "#     xvld_, yvld_ = pd.DataFrame(xtrn).iloc[vld_ind], pd.DataFrame(ytrn).iloc[vld_ind]\n",
    "#     xgb = XGBClassifier()\n",
    "#     xgb.fit(xtrn_, ytrn_)\n",
    "\n",
    "#     yprd_ = xgb.predict(xvld_)\n",
    "\n",
    "#     print(f\"Fold {fold}\")\n",
    "#     fold+=1\n",
    "#     print(classification_report(yvld_, yprd_))\n",
    "\n",
    "#     models.append(xgb)\n",
    "\n",
    "# pred = models[0].predict(xtst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#f. Perceptron\n",
    "\n",
    "# model = Perceptron()\n",
    "# model.fit(xtrn, ytrn)\n",
    "# yprd = model.predict(xvld)\n",
    "\n",
    "# print(classification_report(yvld, yprd))\n",
    "\n",
    "# pred = model.predict(xtst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#g. Perceptron + KFold\n",
    "\n",
    "model = Perceptron()\n",
    "model.fit(xtrn, ytrn)\n",
    "yprd = model.predict(xvld)\n",
    "\n",
    "print(classification_report(yvld, yprd))\n",
    "\n",
    "pred = model.predict(xtst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "outp = pd.DataFrame()\n",
    "\n",
    "outp['id'] = test['id']\n",
    "outp['Class'] = pred\n",
    "\n",
    "outp.to_csv('.\\\\attempt18.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
